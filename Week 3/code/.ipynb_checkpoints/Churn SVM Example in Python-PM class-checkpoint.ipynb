{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods, SVMs, Tuning and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like R, Python uses packages in data mining/machine learning. The 3 mose common ones are Pandas (manipulation), Scikit Learn (machine learning) and Matplotlit (graphics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mpgartland/Documents/Courses/Predictive Models/Pred_Models_git/Week 3/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mpgartland/Documents/Courses/Predictive Models/Pred_Models_git/Week 3\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/mpgartland/Documents/Courses/Predictive Models/Pred_Models_git/Week 3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "# Churn Calls Data\n",
    "This is a Pandas operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "0    AK               1  area_code_408                 no              no   \n",
       "1    AK              36  area_code_408                 no             yes   \n",
       "2    AK              36  area_code_415                yes             yes   \n",
       "3    AK              41  area_code_415                 no              no   \n",
       "4    AK              42  area_code_415                 no              no   \n",
       "5    AK              48  area_code_415                 no             yes   \n",
       "6    AK              50  area_code_408                 no              no   \n",
       "7    AK              51  area_code_510                yes             yes   \n",
       "8    AK              52  area_code_408                 no              no   \n",
       "9    AK              52  area_code_415                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                      0              175.2               74   \n",
       "1                     30              146.3              128   \n",
       "2                     19              171.9               96   \n",
       "3                      0              159.3               66   \n",
       "4                      0              171.0              129   \n",
       "5                     37              211.7              115   \n",
       "6                      0              183.6              107   \n",
       "7                     12              135.8               60   \n",
       "8                      0              217.0              104   \n",
       "9                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              1   yes  \n",
       "3                              1    no  \n",
       "4                              0    no  \n",
       "5                              1    no  \n",
       "6                              1    no  \n",
       "7                              2    no  \n",
       "8                              2    no  \n",
       "9                              2    no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"data/Churn_Calls.csv\", sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['state', 'account_length', 'area_code', 'international_plan',\n",
      "       'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes',\n",
      "       'total_day_calls', 'total_day_charge', 'total_eve_minutes',\n",
      "       'total_eve_calls', 'total_eve_charge', 'total_night_minutes',\n",
      "       'total_night_calls', 'total_night_charge', 'total_intl_minutes',\n",
      "       'total_intl_calls', 'total_intl_charge',\n",
      "       'number_customer_service_calls', 'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# See each collum name\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target \n",
    "In this step I took the target variable and moved it to the first collum. I aslo made a reference to it called targetName. This just helps me with some below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  churn state  account_length      area_code international_plan  \\\n",
       "0    no    AK               1  area_code_408                 no   \n",
       "1    no    AK              36  area_code_408                 no   \n",
       "2   yes    AK              36  area_code_415                yes   \n",
       "3    no    AK              41  area_code_415                 no   \n",
       "4    no    AK              42  area_code_415                 no   \n",
       "5    no    AK              48  area_code_415                 no   \n",
       "6    no    AK              50  area_code_408                 no   \n",
       "7    no    AK              51  area_code_510                yes   \n",
       "8    no    AK              52  area_code_408                 no   \n",
       "9    no    AK              52  area_code_415                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              175.2               74   \n",
       "1             yes                     30              146.3              128   \n",
       "2             yes                     19              171.9               96   \n",
       "3              no                      0              159.3               66   \n",
       "4              no                      0              171.0              129   \n",
       "5             yes                     37              211.7              115   \n",
       "6              no                      0              183.6              107   \n",
       "7             yes                     12              135.8               60   \n",
       "8              no                      0              217.0              104   \n",
       "9             yes                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              0  \n",
       "5                              1  \n",
       "6                              1  \n",
       "7                              2  \n",
       "8                              2  \n",
       "9                              2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name\n",
    "targetName = 'churn'\n",
    "# move target variable into first column\n",
    "targetSeries = df[targetName]\n",
    "del df[targetName]\n",
    "df.insert(0, targetName, targetSeries)\n",
    "expected=targetName\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Just a touch of EDA. This is the distribution of the target. As you can see, the datset is imbalanced and the target class of interest \"yes\" is in the minority (a common occurance in classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x11534a4a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAERCAYAAACdPxtnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQFJ6pgRkKSOGQFJ6pgRkKSO/T9O4oLMmD/abgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11533f080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "The below two steps are for preprocessing. The first cell changes the yes/no of the target to numeric. I needed to do this as some models require the target to be numeric. The second cell takes all the category features and creates dummies with them. This is stock code I have used for long time (and I did not write it). It is nice because it will take any dataframe of any size and handle categorial features. I do not have to change a single line in it. It can be used generically on bascially any dataframe. Saves a lot of time of coding each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "df['churn'] = le_dep.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform data transformation\n",
    "for col in df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df[col].dtype\n",
    "\tmissing = pd.isnull(df[col]).any()\n",
    "\tuniqueCount = len(df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\t\tdel df[attName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train\n",
    "I split the data into a 60/40 train test. The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\". I used a biggest test when I have an imbalanced set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into testing and training\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    df.iloc[:,1:].values, df.iloc[:,0].values, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a view of the size of each test/train set.\n",
    "Note there are now 73 features, and the test set is imbalanced (14.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 73)\n",
      "(3000, 73)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Percent of Target that is Yes 0.146\n"
     ]
    }
   ],
   "source": [
    "print(features_test.shape)\n",
    "print(features_train.shape)\n",
    "print(target_test.shape)\n",
    "print(target_train.shape)\n",
    "print(\"Percent of Target that is Yes\", target_test.mean())\n",
    "#data.groupby(['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "All the models are done in Sci-Kit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "I created a decision tree from the data. The accurancy of the model was 921%, while the test data classified at 92%. However notice that the \"yes\" class (the class I am interested in) only properly classified at 74% (specificity) and .71 (recall). That is so-so. Again, not uncommon with imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.9195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Fail = no       0.95      0.95      0.95      1708\n",
      " Fail = yes       0.72      0.73      0.72       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "from sklearn import tree \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "# print classification report\n",
    "target_names = [\"Fail = no\", \"Fail = yes\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation of Decision Tree\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .92, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.92026578  0.90365449  0.9269103   0.93687708  0.92358804  0.94648829\n",
      "  0.9264214   0.93311037  0.93311037  0.91638796]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92668140757119521"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1627   81]\n",
      " [  80  212]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD0CAYAAAC4n8I2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGERJREFUeJzt3Xm0HGWZx/HvjwQSAgGFoEIIBjHAIEeQbRCPDA4KqAiO\nZ1QUXBkRVEbEDQQHdFw4o4P7BoJBUQRRxgygEXEQ8bAFZItAAJHNAAFkERSSe5/5431bmsu93dXd\n1bduV/8+nDp0V1VXvdW5/fS7dT2KCMzMerVa1QUws3pwMDGzUjiYmFkpHEzMrBQOJmZWCgcTMyuF\ng4mZlcLBpGKS1pT0v5IekvSjHo6zv6RflFm2qkh6qaQbqy6HdUaetFaMpDcDhwNbAo8AVwGfjoiL\nejzuW4BDgV0iYlXPBZ3iJAWwICJurrosVq7pVRdgEEg6HDgCOBhYDDwB7AnsA/QUTIDnAsuGIZAU\nIWn6ML0Xe75srbj/gZFC+15xzeOLI2KvPhepexHhpcUCrAv8BXh9i31mAF8E/pSXLwIz8rbdgDuB\nDwL3AsuBd+RtnyAFppX5HAcCxwKnNh17PhDA9Pz87cAfSLWjW4H9m9Zf1PS6XYDLgYfy/3dp2nYB\n8J/Ab/NxfgHMmeDaGuX/SFP5Xwu8ClgGPAB8rGn/nYCLgQfzvl8F1sjbLszX8mi+3jc2Hf+jwN3A\n9xrr8ms2y+fYLj/fCFgB7Fb130YZy3YvnBErl29WaAGWFPh7PTn/O103Zv2hwA3AUuC/mtYfCdwM\n3Ajs2bR+e+DavO3L5FZMq8V9Ju29GJgJnNVin6OAnYFtgW1IH6ijm7Y/hxSU5pICxtckPTMijgE+\nA5weEWtHxEmtCiJpLdI/7CsjYjYpYFw1zn7rAefkfdcHjgfOkbR+025vBt4BPAtYA/hQi1M/h/Qe\nzAX+AzgROID0B/dS4OOSNs37jgAfAOaQ3rvdgfcARMSueZ9t8vWe3nT89Ui1tIOaTxwRt5ACzamS\nZgHfAU6JiAtalHeABCMxWmgpaCHwlNqLpJcB+5Le9xcAn8/rtwL2A16QX/N1SdPyy74BvAtYkJe2\nNSIHk/bWB+6L1lXv/YFPRsS9EbGCVON4S9P2lXn7yog4l/StvEWX5RkFtpa0ZkQsj4il4+zzauCm\niPheRKyKiNNI30qvadrnOxGxLCL+CpxBCoQTWUnqH1oJ/JAUKL4UEY/k8/+eFESJiCsi4pJ83j8C\n3wL+qcA1HRMRj+fyPEVEnEj6hrwU2JAUvGshgFGi0FLoeBEXkmpyzQ4BjouIx/M+9+b1+wI/zO/7\nraT3eCdJGwLr5H/HAL5Lqo225GDS3v3AHEmt+pc2Am5ren5bXvf3Y4wJRo8Ba3dakIh4lNQ0OBhY\nLukcSVsWKE+jTHObnt/dQXnuj4hGw77xYb+naftfG6+XtLmksyXdLelhUs1rTotjA6yIiL+12edE\nYGvgK40PRV2MFvyP9He4pGk5qN2xs82Bl0q6VNKvJe2Y188F7mja7868bm5+PHZ9Sw4m7V0MPE7r\nyPwnUhW9YZO8rhuPArOanj+neWNELI6IV5C+oW8gfcjaladRpru6LFMnvkEq14KIWAf4GKA2r2n5\ntStpbVI/1EnAsbkZVwtBMBLFFlINeYem5YSCp5lOakbuDHwYOENSu3+TjjmYtBERD5H6Cb4m6bWS\nZklaXdLRkh6QdDPpW/9oSRtImpP3P7XLU14F7CppE0nrkjrIAJD0bEn75r6Tx0nNpfEa0+cCm0t6\ns6Tpkt4IbAWc3WWZOjEbeBj4S641HTJm+z3A8woc55mS7pV0HfAlUufjv5H6gr5ZZoGrVmYzZwJ3\nAj+J5DLS38wc0pfLvKb9Ns7r7sqPx65vycGkgIj4b9Ick6NJIwl3kD7kB5E+pHNIIyzXkHrArwQ+\n1eW5zgNOz8e6gqcGgNVyOf5Eahf/E0//sBIR9wN7k0aQ7ieNxOwdEfd1U6YOfYjUufsIqdZ0+pjt\nxwKnSHpQ0htaHOdRUqff7Pz/xnUeDmwnaf8yC12VAEaIQksP/gd4GaRmKKnD/T5gEbCfpBm5A30B\ncFlELAcelrRzrsG8Ffhpu5N40loXJL0YODYi9szPjwSIiM9WWrCakTQfODsitq64KH2zzTZrxOJz\n23UpJRtuvPyKiNih1T6STiMNrc8h1QKPIQ23n0zqZH8C+FBE/CrvfxTwTmAVcFhE/Cyv34E0MrQm\n8DPg0GgTLDxprTvjdVz9Y0VlsQFXeNC3gIh40wSbDphg/08Dnx5n/RJSh3dhDiZmFYremzBThoNJ\ndybquDLrTMBIPWKJO2C7dDmwQNKmktYgzSJcVHGZbAClSWvFlqnOwaQLeQLa+0g/+rseOGOCmajW\npdyReDGwhaQ7JR1YdZn6Q4wUXKY6N3O6lKfFn1t1OeqqRUdirQQwWpNmjoOJWYUCeKImDQQHE7OK\njcbUb8IU4WBiVqE0A9bBxMx6FIiRmjRz6nEVFengJ+DWpWF4j0dDhZapzsGkN7X/Q58Cav0eN5o5\nHho2sx6JkajHd/qUCiZz1psW8+etXnUxCttk7nR22GbmQM0SWHbNrPY7TSEzmcU6Wm+g3uO/8ShP\nxOOFqhIBrGRa2/0GwZQKJvPnrc5li+e139G6tudGrW71amW4NM4vvG+EayZmVpLRAegPKcLBxKxC\nqQPWNRMz65mbOWZWgnQLAgcTM+tRIJ6Ieozm1CMkmg2w0Vit0FKEpJObUoSM3fZBSZHTsTTWHSnp\nZkk3Stqzaf32kq7N275cJM+Og4lZhRodsEWWghYyTl5gSfOAPYDbm9Y517BZXQRiJIothY43fq5h\ngC+Q8ic1TwAsNdew+0zMKtbvDlhJ+wJ3RcTVY1orc4FLmp43cgqvpItcww4mZhWKoJOh4TmSljQ9\nP6FdvmFJs0j5nvfosoiFOZiYVUqdzIC9r11Gv3FsBmwKNGolGwNXStqJknMNO5iYVSiAJ6J/H8OI\nuBZ4VuO5pD8CO0TEfZIWAT+QdDywEU/mGh6R9LCknYFLSbmGv9LuXO6ANatQUOzGSEVvjtRJipCc\nnuUM4PfAz4H3RsRI3vwe4NukTtlbSPmGW3LNxKxiZf42p12KkIiYP+a5cw2b1UHKm1OPBoKDiVml\nBuOWjEU4mJhVyDUTMyuNayZm1rMIsXK0Hh/DelyF2YBK9zNxzcTMeuY7rZlZCVIHrGsmZlYC31Da\nzHrWmE5fBw4mZhXzDaXNrGcRsHLUwcTMepSaOQ4mZlYCz4A1s555aNjMSuJmjpmVxNPpzaxn6e70\nDiZm1qNArBqtR65hBxOzitWlmVOPnh+zAdUYzSnx7vRPS1wu6XOSbpB0jaSzJD2jaZsTl5vVxWis\nVmgpaCFPTzJ+HrB1RLwQWAYcCU5cblYvBWslRWsm4yUuj4hfRMSq/PQSnszW58TlZnVRwZ3W3gmc\nnh87cblZnXQwA7bjxOXNJB0FrAK+30HxCnMwMatQAKuK/2q4m8TlAEh6O7A3sHtuukDJicv72mci\naa/cS3yzpCP6eS6zQVR2ruHxSNoL+AiwT0Q81rRpEbCfpBmSNuXJxOXLgYcl7ZxHcd4K/LTdefpW\nM8m9wl8DXkFqc10uaVFE/L5f5zQbRGX2meTE5buRmkR3AseQRm9mAOflEd5LIuLgiFgqqZG4fBVP\nT1y+EFiTlLS80sTlOwE3R8QfACT9kNR77GBi1hDl/mp4gsTlJ7XYv7TE5f1s5swF7mh6Pm6PsKSD\nJC2RtGTF/SNjN5vVWtmT1qpU+TyTiDghInaIiB02WL8ev1Ew60Rdgkk/mzkT9RSbWRaIkZrcA7af\nV3E5sEDSppLWIE3bXdTH85kNpFFUaJnq+lYziYhVkt4HLAamASdHxNJ+nc9sEEXJHbBV6uuktYg4\nFzi3n+cwG3ThYGJmvRuMztUiHEzMKuaaiZn1zKkuzKwcvqG0mZUhcDPHzErhDlgzK8nf7y4y4BxM\nzCrmZo6Z9SzCwcTMSuI+EzMrxeiog4mZ9SiQmzlmVo6aDOY4mJhVqkYdsPW4xZPZIIuCSwETJC5f\nT9J5km7K/39m07b+Jy6XtE6rpdilmVk7ESq0FLSQpycZPwI4PyIWAOfn56UnLm/VzFlKiofNV9F4\nHsAm7Q5uZu2VOQM2Ii6UNH/M6n1JuXQATgEuAD5KU+Jy4FZJjcTlfyQnLgeQ1Ehc3jJ3zoTBJCLm\nTbTNzMoRAdH/G0o/O2fpA7gbeHZ+XGri8kJXIWk/SR/LjzeWtH2R15lZe2kWbPuFnLi8aTmo83NF\nBz0wnWk7miPpq8DqwK7AZ4DHgG8CO/ajQGZDp/hHu9vE5fdI2jAilkvaELg3r5/0xOW7RMS7gb8B\nRMQDwBoFXmdmbRXrfO1x+HgR8Lb8+G08mYR80hOXr5S0Gjl+SlofGO3oUsxsYiU2OiZIXH4ccIak\nA4HbgDcAVJG4/GvAj4ENJH0iF+QTRS/OzFooedLaBInLAXafYP/SEpe3DSYR8V1JVwAvz6teHxHX\ntXqNmXWgJvPpi06nn0YaLgo8a9asXMMynV7SUcBpwEakXt0fSDqy3wUzGxolTqevUpGayVuBF0XE\nYwCSPg38DvhsPwtmNhSC2tRMigST5WP2m57XmVkJan9DaUlfIMXNB4Clkhbn53sAl09O8cyGQN2D\nCdAYsVkKnNO0/pJx9jWzbtW9mRMRJ01mQcyGUoBqMgW0yG9zNiNNatkKmNlYHxGb97FcZkNCtamZ\nFJkzshD4Duk+Jq8EzgBO72OZzIZLTYaGiwSTWRGxGCAibomIo0lBxczKUJNgUmRo+PH8Q79bJB1M\n+iny7P4Wy2yIDECgKKJIMPkAsBbw76S+k3WBd/azUGZDY5gmrUXEpfnhI8Bb+lscs+GjutdMJJ1F\niwpYRLyuLyUyGzZ1DybAVyetFNmya2ax50bbTvZph8r0eRu338l6ortX72z/ugeTiDh/MgtiNrSG\npc/EzPpoQIZ9i3AwMavasAUTSTNy5i8zK1Fd+kyK3GltJ0nXAjfl59tI+krfS2Y2LMpNXP4BSUsl\nXSfpNEkzu0lc3o0i0+m/DOwN3A8QEVcDL+vlpGaWKP9quMjS9ljSXNLk0h0iYmvSvZv3o7vE5R0r\nEkxWi4jbxqwbGXdPM+tcqNhSzHRgTUnTgVnAn0gJyk/J208hJSGHpsTlEXErcDOwU7eXUSSY3CFp\nJyAkTZN0GLCs2xOa2RjFmzktcw1HxF3A54HbSbdWfSgifkHrxOV3NB2iUILyiRTpgD2E1NTZBLgH\n+GVeZ2Yl6KADtmWu4dwXsi+wKfAg8CNJBzTvExEh9afLt8hvc+4ltavMrB/K+2i/HLg1IlYASPoJ\nsAudJy7vSpE7rZ3IOJcbEQeNs7uZdSJKHRq+HdhZ0izgr6SUoEuAR0kJy4/j6YnLfyDpeFJerAXA\nZd2evEgz55dNj2cC/8JT21lm1ouSgklEXCrpTOBKUiLy3wEnAGvTeeLyjhVp5jzlFo2Svgdc1O0J\nzeypyryhdEQcAxwzZvXjdJi4vBvd5A3elCd7g83MgGJ9Jn/myYrYaqSkXEf0s1BmQ6Um0+lbBhNJ\nArbhyR7e0Yi6JDM0mwLK7YCtVMtmTg4c50bESF5qctlmU0hN7k5fpM/kKkkv6ntJzIZVTYJJq3vA\nTo+IVcCLgMsl3UIarxap0rLdJJXRrLZEfZo5rfpMLgO2A/aZpLKYDZ8hyTUsSFn8JqksZsNpCGom\nG0g6fKKNEXF8H8pjNnyGIJhMI03Drcets82mqGHoM1keEZ+ctJKYDashCCaukZj124AM+xbRKpiM\n+8MgMytX7UdzIuKBySyI2bAahj4TM5sMDiZm1rMh6TMxsz4T9RnpcDAxq5prJmZWBnfAmlk5ajI0\n3M09YM2sLPlOa0WWIiQ9Q9KZkm6QdL2kF0+lxOVm1k/l3hzpS8DPI2JL0i1Xr2cKJS43sz4qq2Yi\naV1gV+AkgIh4IiIeZAolLjezfiopcTkpDc0K4DuSfifp25LWYgolLjezPiorcTnp87wdcGjO7vcl\nxqSl6WfictdMzKpUtFZS7ON/J3BnRFyan59JCi735ITl9DNxuYOJWYVE+tVwkaWdiLgbuEPSFnnV\n7qQ8wotICcvh6YnL95M0Q9KmTELicjPrp3IbHYcC35e0BvAH4B2kSkP1icu7JelkYG/g3ojYul/n\nMRt0KjG3XURcBYzXrzIlE5cXtZA0dm1mEym3z6RSfauZRMSFkub36/hmdeHf5pQkj5UfBDCTWRWX\nxqwCDibliIgTgBMA1tF6NXlbzYpzzcTMejck6UHNbDLUpGbSt9EcSacBFwNbSLozj3GbWRNR7i0I\nqtTP0Zw39evYZrVS4jyTKrmZY1axQah1FOFgYlalAZmQVoSDiVnFPJpjZqVwMDGz3gXugDWzcrgD\n1szK4WBiZr1qTFqrAwcTsypFuM/EzMrh0RwzK4WbOWbWuwBG6xFNnOrCrGol3wNW0rSc0e/s/NyJ\ny82GQR9uQfB+UsLyBicuNxsKjRGddksBkjYGXg18u2m1E5ebDYMOaibtEpcDfBH4CNA8RuTE5WZ1\npwAV74BtmbhcUiPp3RWSdhtvn34mLncwMataefNMXgLsI+lVwExgHUmnkhOXR8RyJy43qzFFFFra\niYgjI2LjiJhP6lj9VUQcgBOXmw2BybnT2nEMcuJyMyuiP7/NiYgLgAvy4/uZhMTlDiZmFfN0ejMr\nh381bGY9C9CIg4mZlaEescTBxKxqRYZ9B4GDiVnVHEzMrGdBmTNgK+VgYlYhUWx26yBwMDGrmoOJ\nmfUsAA8Nm1kZ3Mwxs3I4mJhZ75yEy8zKEDiYmFlJPM/EzMrgDlgz610AI/WomjiYmFXKHbB98Qh/\nvu+XceZtVZejA3OA+6ouREdur7oAHRu89xie29HeDibli4gNqi5DJyQtaZXHxHo3FO9xTYKJU12Y\nVSmA0Si2tCFpnqT/k/R7SUslvT+vd+Jys/oLiNFiS3urgA9GxFbAzsB7c3JyJy4fACdUXYAhUO/3\nuDGaU2Rpd6iI5RFxZX78CHA9KXewE5dPdRHR8g9d0oikqyRdJ+lHkmZ1ey5Ju0k6Oz/eR9IRLfZ9\nhqT3dHGOYyV9qOj6MfsslPSvHZxrvqTr2u3X7j2uhYhiS7HE5UB6f4EXAZfixOW18NeI2BZA0veB\ng4HjGxslCVBEsTpsQ0QsIqV2nMgzgPcAX++4xDb5infAtkxc3iBpbeDHwGER8XD6M2ucqn+Jy10z\nmTy/AZ6fv5FvlPRd4DpgnqQ9JF0s6cpcg1kbQNJekm6QdCXwusaBJL1d0lfz42dLOkvS1XnZhZQO\ncrNcK/pc3u/Dki6XdI2kTzQd6yhJyyRdBGzR7iIkvSsf52pJPx5T23p5/sZcJmnvvP80SZ9rOve7\ne30j66VgraRgwJG0OimQfD8ifpJX35MTluPE5QNO0nTglcC1edUC4OsR8QLgUeBo4OURsR2wBDhc\n0kzgROA1wPbAcyY4/JeBX0fENsB2wFJSB9stEbFtRHxY0h75nDsB2wLbS9pV0vakDrhtgVcBOxa4\nnJ9ExI75fNcDBzZtm5/P8Wrgm/kaDgQeiogd8/HflZNkG+TRnNFiSxu5pnsScH1EHN+0yYnLa2BN\nSVflx78h/UNvBNwWEZfk9TsDWwG/zdXRNYCLgS2BWyPiJgBJpwLjtZH/GXgrQE46/VDz0F+2R15+\nl5+vTfrDmQ2cFRGP5XO0ajo1bC3pU6Sm1NrA4qZtZ+Qm202S/pCvYQ/ghU39Kevmcy8rcK7hUN48\nk5cAbwGubfq7+xhOXF4Lf+8zacgB49HmVcB5EfGmMfs95XU9EvDZiPjWmHMc1sWxFgKvjYirJb0d\n2K1p29hPReRzHxoRzUGn0UFoUFowiYiLSO/3ePqeuNzNnOpdArxE0vMBJK0laXPgBmC+pM3yfm+a\n4PXnA4fk106TtC7wCKnW0bAYeGdTX8xcSc8CLgReK2lNSbNJTap2ZgPLc9t8/zHbXi9ptVzm5wE3\n5nMfkvdH0uaS1ipwnuEQQYyMFFqmOtdMKhYRK/I3/GmSZuTVR0fEsjz0d46kx0jNpNnjHOL9wAm5\nCjsCHBIRF0v6bR56/VnuN/kH4OJcM/oLcEBEXCnpdOBqUqfc5QWK/HHScOOK/P/mMt1OanOvAxwc\nEX+T9G1SX8qVuU2/gifnORgUmt06CBQ1+V2A2SBad/oG8eLZ+xbad/GDJ10xlX+n5JqJWZUiCo3U\nDAIHE7Oq1aR14GBiVrFwzcTMeuc7rZlZGQIYgGHfIhxMzCoUQNRkaNjBxKxKEUVvfDTlOZiYVawu\nNRNPWjOrkKSfk+7AX8R9EbFXP8vTCwcTMyuFf+hnZqVwMDGzUjiYmFkpHEzMrBQOJmZWCgcTMyuF\ng4mZlcLBxMxK4WBiZqX4fyr8UGVatl09AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11354b8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_dt)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "Using the same data, I built a random forest with 500 bootstrapped trees. Notice I parallelized this to 4 cores as big random forest can be computationally expensive. \n",
    "\n",
    "My overall results went up by 3% over the decision tree. Also, my minory target precision, but the recall decresed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.95      1.00      0.97      1708\n",
      "Churn = yes       0.97      0.70      0.81       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1701    7]\n",
      " [  89  203]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "#paralleized to 4 cores \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(accuracy_score(target_test, target_predicted_rf))\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Random Forest\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .949, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.94352159  0.94019934  0.94352159  0.95681063  0.93687708  0.94983278\n",
      "  0.94983278  0.94983278  0.94314381  0.95652174]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94700941121568027"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score for each K\",scores_rf)\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual of Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1696   12]\n",
      " [  98  194]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD0CAYAAAC4n8I2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng4mZleL/ASqW6BkYL8OrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117e40b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_rf)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "You can tune any argument in these models. I did a grid search only on max_features (mtry in R). I parallelized the job to 4 cores for speed. You can see that max_features (mtry) of 5 had the best results. But frankly was very little difference from the other parameter results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 3.6882099999999998 seconds\n",
      "{'split0_test_score': array([ 0.88011988,  0.89010989,  0.9020979 ,  0.90909091]), 'split1_test_score': array([ 0.894,  0.909,  0.919,  0.928]), 'split2_test_score': array([ 0.89289289,  0.9039039 ,  0.91791792,  0.92592593]), 'mean_test_score': array([ 0.889,  0.901,  0.913,  0.921]), 'std_test_score': array([ 0.00630013,  0.00798201,  0.00772736,  0.00846973]), 'rank_test_score': array([4, 3, 2, 1], dtype=int32), 'split0_train_score': array([ 1.,  1.,  1.,  1.]), 'split1_train_score': array([ 1.,  1.,  1.,  1.]), 'split2_train_score': array([ 1.,  1.,  1.,  1.]), 'mean_train_score': array([ 1.,  1.,  1.,  1.]), 'std_train_score': array([ 0.,  0.,  0.,  0.]), 'mean_fit_time': array([ 3.39331937,  3.65042162,  3.81190022,  3.66277281]), 'std_fit_time': array([ 0.13094076,  0.2608817 ,  0.21933537,  0.14806462]), 'mean_score_time': array([ 0.42837167,  0.34965277,  0.39610044,  0.2399536 ]), 'std_score_time': array([ 0.07504435,  0.04994216,  0.05566358,  0.05015319]), 'param_max_features': masked_array(data = [2 3 4 5],\n",
      "             mask = [False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': ({'max_features': 2}, {'max_features': 3}, {'max_features': 4}, {'max_features': 5})}\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5]}\n",
    "start_time = time.clock()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")\n",
    "print(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "I performed KNN on K=3 and K=5. For both K's the accurancy was 85% and 87% respectively and I still have problems with the minority class. KNN and Decision Tree perform about the same. I find this to be true frequently, which is why I use them as my base comparative models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Details\n",
    "Now that we know our random forest was the best model of the three I ran, I will gather some other information. Below is a non-ordered list of feature importance. I only showed 20 for purposes of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "Higher the more important\n",
      "[(0.12839999999999999, 'total_day_charge'), (0.12740000000000001, 'total_day_minutes'), (0.10009999999999999, 'number_customer_service_calls'), (0.055, 'total_eve_minutes'), (0.054800000000000001, 'total_eve_charge'), (0.047, 'total_intl_calls'), (0.042500000000000003, 'total_intl_minutes'), (0.040399999999999998, 'total_intl_charge'), (0.036799999999999999, 'total_night_minutes'), (0.036799999999999999, 'total_night_charge'), (0.0327, 'account_length'), (0.0298, 'total_night_calls'), (0.029600000000000001, 'total_day_calls'), (0.028500000000000001, 'total_eve_calls'), (0.016799999999999999, 'number_vmail_messages'), (0.002, 'state_AZ'), (0.0019, 'state_AR'), (0.00069999999999999999, 'state_AL'), (0.00069999999999999999, 'state_AK')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Features sorted by their score:\")\n",
    "print(\"Higher the more important\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_),df.columns[1:20]), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve for Random Forest\n",
    "Finally a ROC curve that shows the lift I get from the Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.921\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119044b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('ROC AUC: %0.3f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest does the best, but I still am not getting the accurancy on my target class of interest. I have a few tricks I can do to work on this, but that is for another day/class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SVM with L2 penalty, Cost function of 1 and auto class weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.88      0.96      0.92      1708\n",
      "        Yes       0.52      0.22      0.31       292\n",
      "\n",
      "avg / total       0.83      0.86      0.83      2000\n",
      "\n",
      "[[1648   60]\n",
      " [ 227   65]]\n",
      "0.8565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='balanced')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "predicted_SVC=clf_linSVC.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVC))\n",
    "print(accuracy_score(expected,predicted_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC kernel= linear\n",
    "# Change Class_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n",
      "148.145937 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight=None,gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print(accuracy_score(expected,predicted_SVM))\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.74      0.84      1708\n",
      "        Yes       0.35      0.80      0.49       292\n",
      "\n",
      "avg / total       0.87      0.75      0.79      2000\n",
      "\n",
      "[[1271  437]\n",
      " [  57  235]]\n",
      "0.753\n",
      "Time to run 141.223871 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print(accuracy_score(expected,predicted_SVM))\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search of Cost Function (with cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This take a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES {'split0_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86666667,  0.86666667,\n",
      "        0.87      ,  0.86666667]), 'split1_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.87666667,  0.88      ,\n",
      "        0.87833333,  0.875     ]), 'split2_test_score': array([ 0.86166667,  0.86166667,  0.86333333,  0.865     ,  0.87166667,\n",
      "        0.86833333,  0.87833333]), 'split3_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.87      ,  0.87      ,\n",
      "        0.87      ,  0.87333333]), 'split4_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.87166667,  0.875     ,\n",
      "        0.87166667,  0.87166667]), 'mean_test_score': array([ 0.86166667,  0.86166667,  0.862     ,  0.87      ,  0.87266667,\n",
      "        0.87166667,  0.873     ]), 'std_test_score': array([ 0.        ,  0.        ,  0.00066667,  0.00408248,  0.00454606,\n",
      "        0.00349603,  0.00385861]), 'rank_test_score': array([6, 6, 5, 4, 2, 3, 1], dtype=int32), 'split0_train_score': array([ 0.86166667,  0.86166667,  0.86208333,  0.87458333,  0.87833333,\n",
      "        0.88541667,  0.88      ]), 'split1_train_score': array([ 0.86166667,  0.86166667,  0.8625    ,  0.87375   ,  0.87791667,\n",
      "        0.88      ,  0.87833333]), 'split2_train_score': array([ 0.86166667,  0.86166667,  0.86208333,  0.87208333,  0.87458333,\n",
      "        0.87666667,  0.88041667]), 'split3_train_score': array([ 0.86166667,  0.86166667,  0.86625   ,  0.87708333,  0.87958333,\n",
      "        0.87833333,  0.87958333]), 'split4_train_score': array([ 0.86166667,  0.86166667,  0.86208333,  0.8725    ,  0.87708333,\n",
      "        0.87666667,  0.87958333]), 'mean_train_score': array([ 0.86166667,  0.86166667,  0.863     ,  0.874     ,  0.8775    ,\n",
      "        0.87941667,  0.87958333]), 'std_train_score': array([ 0.        ,  0.        ,  0.00163299,  0.00177951,  0.00166667,\n",
      "        0.00324465,  0.00069722]), 'mean_fit_time': array([  33.1759726 ,   66.23090143,  213.15018587,  380.70834494,\n",
      "        524.98431983,  694.51413894,  508.80119486]), 'std_fit_time': array([   8.16556865,    8.12025939,   38.30606259,   86.1358593 ,\n",
      "        119.34603882,   69.36155813,   55.02453727]), 'mean_score_time': array([ 0.05828543,  0.08076515,  0.07719703,  0.05405555,  0.05418458,\n",
      "        0.04460754,  0.03677874]), 'std_score_time': array([ 0.0094737 ,  0.02897304,  0.0166671 ,  0.00839968,  0.00656458,\n",
      "        0.00138574,  0.00485135]), 'param_C': masked_array(data = [0.01 0.05 1 3 4 9 10],\n",
      "             mask = [False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': ({'C': 0.01}, {'C': 0.05}, {'C': 1}, {'C': 3}, {'C': 4}, {'C': 9}, {'C': 10})}\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'C': 10}\n",
      "Time to run 266.23299099999997 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[.01,.05,1,3,4,9,10]}\n",
    "svr = SVC(kernel='linear')\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print(\"SCORES\", grid_svm.cv_results_)\n",
    "print(\"BEST SCORE\", grid_svm.best_score_)\n",
    "print(\"BEST PARAM\", grid_svm.best_params_)\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search of Several Functions (with cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This take a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES {'split0_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86166667,\n",
      "        0.86166667,  0.86666667,  0.86166667,  0.86833333,  0.86166667,\n",
      "        0.86666667,  0.86166667]), 'split1_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86166667,\n",
      "        0.86166667,  0.87666667,  0.86166667,  0.87666667,  0.86166667,\n",
      "        0.875     ,  0.86166667]), 'split2_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86333333,\n",
      "        0.86166667,  0.865     ,  0.86166667,  0.875     ,  0.86166667,\n",
      "        0.87833333,  0.86166667]), 'split3_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86166667,\n",
      "        0.86166667,  0.87      ,  0.86166667,  0.87      ,  0.86166667,\n",
      "        0.87333333,  0.86166667]), 'split4_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86166667,\n",
      "        0.86166667,  0.87166667,  0.86166667,  0.86833333,  0.86166667,\n",
      "        0.87166667,  0.86166667]), 'mean_test_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.862     ,\n",
      "        0.86166667,  0.87      ,  0.86166667,  0.87166667,  0.86166667,\n",
      "        0.873     ,  0.86166667]), 'std_test_score': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.00066667,\n",
      "        0.        ,  0.00408248,  0.        ,  0.00349603,  0.        ,\n",
      "        0.00385861,  0.        ]), 'rank_test_score': array([5, 5, 5, 5, 4, 5, 3, 5, 2, 5, 1, 5], dtype=int32), 'split0_train_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86208333,\n",
      "        1.        ,  0.87458333,  1.        ,  0.88041667,  1.        ,\n",
      "        0.88      ,  1.        ]), 'split1_train_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.8625    ,\n",
      "        1.        ,  0.87375   ,  1.        ,  0.87541667,  1.        ,\n",
      "        0.87833333,  1.        ]), 'split2_train_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86208333,\n",
      "        1.        ,  0.87208333,  1.        ,  0.8775    ,  1.        ,\n",
      "        0.88041667,  1.        ]), 'split3_train_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86625   ,\n",
      "        1.        ,  0.87708333,  1.        ,  0.8775    ,  1.        ,\n",
      "        0.87958333,  1.        ]), 'split4_train_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.86208333,\n",
      "        1.        ,  0.8725    ,  1.        ,  0.87791667,  1.        ,\n",
      "        0.87958333,  1.        ]), 'mean_train_score': array([ 0.86166667,  0.86166667,  0.86166667,  0.86166667,  0.863     ,\n",
      "        1.        ,  0.874     ,  1.        ,  0.87775   ,  1.        ,\n",
      "        0.87958333,  1.        ]), 'std_train_score': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.00163299,\n",
      "        0.        ,  0.00177951,  0.        ,  0.00159426,  0.        ,\n",
      "        0.00069722,  0.        ]), 'mean_fit_time': array([  4.29884591e+00,   2.43650770e-01,   2.85779255e+01,\n",
      "         8.75129223e-01,   1.90644154e+02,   1.25355458e+00,\n",
      "         3.49244402e+02,   1.26186185e+00,   6.13488852e+02,\n",
      "         1.40192966e+00,   6.48751199e+02,   1.30650640e+00]), 'std_fit_time': array([  3.36102468e-01,   8.15791935e-03,   6.10380707e+00,\n",
      "         1.90550798e-02,   3.24188307e+01,   2.03612348e-01,\n",
      "         8.05295138e+01,   1.41700249e-01,   1.19988587e+02,\n",
      "         2.37741059e-01,   7.67014264e+01,   2.47129951e-01]), 'mean_score_time': array([ 0.04644732,  0.0546402 ,  0.04702029,  0.20572   ,  0.06775775,\n",
      "        0.26946521,  0.06266141,  0.22204838,  0.06104636,  0.25040255,\n",
      "        0.04347506,  0.24092751]), 'std_score_time': array([ 0.00123402,  0.00441186,  0.00054383,  0.00630749,  0.03088439,\n",
      "        0.07383523,  0.013546  ,  0.01717785,  0.0133976 ,  0.0310762 ,\n",
      "        0.00485017,  0.04115427]), 'param_C': masked_array(data = [0.001 0.001 0.01 0.01 1 1 3 3 5 5 10 10],\n",
      "             mask = [False False False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_kernel': masked_array(data = ['linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf'\n",
      " 'linear' 'rbf'],\n",
      "             mask = [False False False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': ({'C': 0.001, 'kernel': 'linear'}, {'C': 0.001, 'kernel': 'rbf'}, {'C': 0.01, 'kernel': 'linear'}, {'C': 0.01, 'kernel': 'rbf'}, {'C': 1, 'kernel': 'linear'}, {'C': 1, 'kernel': 'rbf'}, {'C': 3, 'kernel': 'linear'}, {'C': 3, 'kernel': 'rbf'}, {'C': 5, 'kernel': 'linear'}, {'C': 5, 'kernel': 'rbf'}, {'C': 10, 'kernel': 'linear'}, {'C': 10, 'kernel': 'rbf'})}\n",
      "BEST Estm SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'C': 10, 'kernel': 'linear'}\n",
      "Time to run 263.3796080000001 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "from sklearn.svm import SVC\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[.001,.01,1,3,5,10]}\n",
    "svr = SVC()\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print(\"SCORES\", grid_svm.cv_results_)\n",
    "print(\"BEST Estm\",grid_svm.best_estimator_) \n",
    "print(\"BEST SCORE\",grid_svm.best_score_)\n",
    "print(\"BEST PARAM\", grid_svm.best_params_)\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does \"Best\" perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.71      0.82      1708\n",
      "        Yes       0.32      0.79      0.46       292\n",
      "\n",
      "avg / total       0.86      0.73      0.76      2000\n",
      "\n",
      "[[1221  487]\n",
      " [  62  230]]\n",
      "0.7255\n",
      "Time to run 729.06263 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print(accuracy_score(expected,predicted_SVM))\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using a RBF (non-linear) Kernel (High dimensional Space). Untuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      1.00      0.92      1708\n",
      "        Yes       0.00      0.00      0.00       292\n",
      "\n",
      "avg / total       0.73      0.85      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 292    0]]\n",
      "0.854\n",
      "Time to run 1.439623999999867 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpgartland/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=1.0, degree=3, class_weight='balanced',gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_rbf,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_rbf))\n",
    "print(accuracy_score(expected,predicted_rbf))\n",
    "print(\"Time to run\", time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Polynominal Kernel (2nd Degree), untuned.\n",
    "Would not fit at 2nd and 3rd degree given 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1.0,class_weight=None)\n",
    "clf_poly.fit(features_train, target_train)\n",
    "predicted_poly=clf_poly.predict(features_test)\n",
    "expected = target_test\n",
    "#summarize the fit of the model\n",
    "print(classification_report(expected, predicted_poly,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_poly))\n",
    "print accuracy_score(expected,predicted_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
